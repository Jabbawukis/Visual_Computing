{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exercise we will repeat our experiment from the first part, however, this time we are going to use PyTorch to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "train_data = MNIST(root=\"./\", train=True, transform=None, target_transform=None, download=True)\n",
    "test_data = MNIST(root=\"./\", train=False, transform=None, target_transform=None, download=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to experiment with the nn Module of torch. This module can be used to create layers of neural networks.\n",
    "Refer to this tutorial for more info: https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html\n",
    "\n",
    "Instantiate a convolutional layer with kernel size 3, stride 1 and zero_padding_dim of 0. nn Modules except torch tensors instead of numpy arrays as inputs, these can easily be constructed with the torch.tensor() or torch.from_numpy() commands. Note that the torch conv layer (unlike the one we built in the previous exercise) requires that the channel in- and output-dimensions are specififed as well.\n",
    "Given that MNIST are grayscale images, we need to artificially add a dimension of size 1 to our tensors, this can be done with the unsqueeze method.\n",
    "\n",
    "After the instantiation, create a dummy input and forward it through the conv layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and test Conv2d here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next task is to rebuild the simple_cnn from the previous exercise. This time, add a MaxPooling \"layer\" with kernel size 2 and stride 2 after the ReLu activation (https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html). Set the kernel size of the conv layer to 3, stride to 1 and padding to 0. Calculate the necessary input dimension of the fully connected (also called linear) layer, given that the input is of dim (batch_size, 1, 28, 28). You can do that by hand or just try to forward a dummy input through the Convolution and MaxPooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_cnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_cnn, self).__init__()\n",
    "\n",
    "        # define layers and activations here\n",
    "        self.conv = ...\n",
    "        self.relu = ...\n",
    "        self.pool = ...\n",
    "        self.fc = ...\n",
    "        self.softmax = ...\n",
    "\n",
    "    # define forward pass here\n",
    "    def forward(self, x):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your cnn here\n",
    "# load cnn\n",
    "\n",
    "# load input\n",
    "input = train_data.__getitem__(0)[0]\n",
    "input = np.array(input)\n",
    "input = torch.tensor(input).float().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# forward, check output dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we already met this function\n",
    "def label_one_hot_encoding(x, dim=10):\n",
    "    output = np.zeros(dim)\n",
    "    output[x] = 1\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to train our simple_cnn. Similar to the previous exercise, build a training loop but use the pytorch SGD optimizer to update the weights. (We don't need to manually calculate the gradients anymore!). Try out different learning rates and monitor the loss to identify conversion.\n",
    "\n",
    "Refer to this tutorial: https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = simple_cnn()\n",
    "batch_size = ...\n",
    "learning_rate = ...\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD()\n",
    "\n",
    "num_samples = len(train_data)\n",
    "num_epochs = ...\n",
    "\n",
    "for i in range():\n",
    "    # load and build input and target tensors here\n",
    "    ...\n",
    "\n",
    "    # perform forward / obtain prediction\n",
    "    pred = ...\n",
    "\n",
    "    # calculate loss\n",
    "    loss = ...\n",
    "\n",
    "    # perform backprop and gradient descent\n",
    "    ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as before, compute the accuracy on the test data. Try to train multiple models with different specs and learning rates in order to achieve the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model to eval mode, this kills dropout cells etc. not relevant for our model but still important\n",
    "cnn.eval()\n",
    "\n",
    "num_test_samples = len(test_data)\n",
    "\n",
    "for i in range(num_test_samples):\n",
    "    # load and build input and target tensors\n",
    "    ...\n",
    "\n",
    "    # forward\n",
    "    pred = ...\n",
    "\n",
    "    # update accuracy or save results\n",
    "    ...\n",
    "\n",
    "# print accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
