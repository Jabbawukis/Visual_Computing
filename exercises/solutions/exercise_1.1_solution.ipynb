{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beckmann/miniconda3/envs/deepfake/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "train_data = MNIST(root=\"./\", train=True, transform=None, target_transform=None, download=True)\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE885B72550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = train_data.__getitem__(0)[0]\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE8832F5950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nGNgGArA+YU6AwMDAwMTAwMDg10gqqTpGQaEpEMQihyTohwjgndnMYqk9L9FSDqZUE2dw3AbIaknjirJz7AbIenFiSInrsjwFCGpznAVWbJH/NZnCIuFgYGBgeE0XIbPI8aNofkDsqQQAwODPpOzDFs00/eTP1nOQlUyMjAwTEv/8IiBQY/xz7drJ88cfPlEkI0BoTProRUDA8OjjddOMDAwMKSJ3mPACVb+64QxmbBIb8AnyYBHklEVj+R/JjySDJb4jMVj5/b/OB1IJQAAg3ksR3QPgSAAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE885B68910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGPyg5u9/e1xyCV9+/7WDMJkwJOXZcRvq8ub3ZXkO7HI2T37/jsOlcfbfv3txyYn8/f3aCYecwtm/v+twacz4/XcHPw65gA+/D4rjMvTv37/zcRk6/ffv3+o45Azu/v69BpfGV79/H+HBJfn39+9IXHLz///9K4/Lxid/v/fgCHAGh99/76CLYcYnNskbx/ApoyoAAGeYO0QsY6cRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE885B68F50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nN3QPwtBYRQG8EMU0e0uZLIw+QKXRZlMGC0GX8CglE0pk0VxPwQmE5YrJYPVIjYMlImSwXNiMOi97319AM/6O6fzh+g/Y5hr5mrRNByseAZba4D7EnlSN8wy3uAYXJOwDEw0ohKwD9mtxehqRLQBCnZr8GPkJ/Ll79y0m37GiIjiK2AQsGMYiIbryyvjmZO20U9gAIcjTg43GhfethOROToO+En6xRUlZhnSjd+I6BY7xVIRY79w4XapR9IOSTWWYSWUqE0xlH771R7UrULefm5U2pxVCt0AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE8832EBB90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABD0lEQVR4nGNgGGSAEY3Py+Mt1vsTq1LF6Rf+/PkzCZuUxowvf/4+uPznhQaGFP+M93/+/Lkhr/rnjw2GZMKfP3/+3JRlQJJkgkuGMjA8WO36mAHJTBY4KzVt151XDAwM4ti9BQFzEcayoEjkcTP+12U4dhxTC5fp5r9////9+0QZQ4rV7PGfz09Wffrz53kpG5ocm9+fP7XWDEIX/vz58yecHVVf+58/WwQYRE///d649s+fHU6GhnA55o4/H7MEGUxP/LnhyMDnsfjjnz/34ZKZfz5FCHmu+vKnTpaBgYGBIXLLFlW45PM/X8/e+PPnTw0zFo+f//Pnz59NJSqovoZGNm+A0at5739h0Ta4AABroXIjERrLHgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE885B72550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAh0lEQVR4nGNgGGAw8f9leVxyCm///nFHFmBCYr8+hKYaWfLrQzySAvp4JLnkGBhMcbqo9u+fPzm4JBnQJJlQJJkYGZG5LCiS//7jdBAGIEGSiZHRDqfSv3/+/NHCpXMGAwNDGi7JG/hcwHDr79//yjh0Mlz9//8fLmMZZqHw0CSvXcdrKx0AAOciI63Ko1kqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE885B68F50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEklEQVR4nM2RMS+DURiFn/ullKXC1KWJyVId2ARBQpqUHyBRC0NjsPsPNktj0F9QEgYiIvEDJG3CYhEpMTBI2qEk5+YzfP1uuD6bwVnum3ve877n5IV/jLH8Vmittfao36fyuw8tWUmSahmPPJEUk5oGIOXIixIvNRMyNZewMZXLZQEyLame9pR6jN7iMDx9JFtevZTk+4mwdtuVdD2IN3Z0fRFmQmjvnHY9TeE+jnLs/gJXGWOMCYwxKyUXIC5u5svn78DmdrJRAIYkpwx8svizv2+5536j/UUZYfZMOYCR8pvUWXAeAWiOU+0AS5MhV9XD78pm71Kyz/sD/sqJA0nSXWOvkBAgXXlVvZL9Jd4f4xPJmHJ5CeNkqwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE885E90F10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAc0lEQVR4nGNgGMyA1f4obkmRf88kkPlMqNIS+CQZGfBI/ufEI8lgjFPyz0cGZZySHw6jGoNuLF5JYXySfrgl9+Mz9hEDqzxOyT8MjOy43Xft3zTckhM+cuA0loHh/y88knwBuI199l0Dt85Dt77j1kktAADVQhZzhi0BcQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE8832EBB90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7klEQVR4nM3QsUtCURiG8QdRFIKEoCHIGtouSM4SRn9CixE0REtjS4tu0tLm4tIS4tLeFqE0FNjukIqLDrchCBq85H1Pt6Gl7vGs4bed78cDHwcWZtodgMRcqxeHzu4y+Cg78UH39rJ0twJw+NbftvHF7AD0ov2f95+DplEGKGx8ZezwIuytwtKNnlKW5V6DXeBKY7vLD1UHzj91GqfksYlMt5pee55dW92RZPpSdyLfsoMw8PcKbckonGzFsDM6AbxHGakVL89yAKV3lT1v2T4WyDbMYC4AVOSvu2xzFNac4UDN2ObXxze5dYb/N9+FeFNxEamP7gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE8832E6E10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    img = train_data.__getitem__(i)[0]\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(train_data.__getitem__(0)[0])\n",
    "label = np.array(train_data.__getitem__(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_layer():\n",
    "    def __init__(self, kernel_size: int, zero_padding_size: int, stride: int, weights: list = None):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.zero_padding_size = zero_padding_size\n",
    "        self.stride = stride\n",
    "\n",
    "        if weights is not None:\n",
    "            self.weights = np.array(weights)\n",
    "            self.kernel_size = len(weights)\n",
    "        else:\n",
    "            self.weights = np.random.rand(kernel_size, kernel_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.shape[0]\n",
    "        input_shape = input.shape[1]\n",
    "        output_shape = int(np.ceil((input_shape + 2*self.zero_padding_size - self.kernel_size) / self.stride) + 1)\n",
    "\n",
    "        padded_input = np.pad(input, ((0, 0), (self.zero_padding_size, self.zero_padding_size), (self.zero_padding_size, self.zero_padding_size)))\n",
    "        output = np.zeros((batch_size, output_shape, output_shape))\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for i in range(output_shape):\n",
    "                for j in range(output_shape):\n",
    "                    patch = padded_input[b, i*self.stride:i*self.stride+self.kernel_size, j*self.stride:j*self.stride+self.kernel_size]\n",
    "                    output[b, i, j] = np.sum(patch*self.weights)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.array([[1,1,1,0,0], [0,1,1,1,0], [0,0,1,1,1], [0,0,1,1,0], [0,1,1,0,0]])\n",
    "input = np.expand_dims(input, 0)\n",
    "weights = [[0,0,1], [0,1,1], [1,1,1]]\n",
    "\n",
    "layer = conv_layer(3, 1, 1, weights)\n",
    "output = layer.forward(input)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fc_layer():\n",
    "    def __init__(self, in_channels: int, out_channels: int, weights: list = None):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        if weights is not None:\n",
    "            self.weights = np.array(weights)\n",
    "        else:\n",
    "            self.weights = np.random.rand(self.in_channels, self.out_channels)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return np.matmul(input, self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_vals = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_vals / np.sum(exp_vals, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_cnn():\n",
    "    def __init__(self, conv_layer, fc_layer):\n",
    "        self.conv_layer = conv_layer\n",
    "        self.fc_layer = fc_layer\n",
    "\n",
    "    def forward(self, input):\n",
    "        features = self.conv_layer.forward(input)\n",
    "        features = relu(features)\n",
    "        features = features.reshape(features.shape[0], features.shape[1]**2)\n",
    "        output = self.fc_layer.forward(features)\n",
    "        output = softmax(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 28 28\n",
      "(2, 10)\n"
     ]
    }
   ],
   "source": [
    "input = np.random.rand(2, 28, 28)\n",
    "cl = conv_layer(3, 1, 1, None)\n",
    "fc = fc_layer(28**2, 10)\n",
    "cnn = simple_cnn(cl, fc)\n",
    "out = cnn.forward(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_one_hot_encoding(x, dim=10):\n",
    "    output = np.zeros(dim)\n",
    "    output[x] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(target, pred):\n",
    "    return np.mean(np.sum((target-pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_mse_to_fc(input, target, pred, fc_weights):\n",
    "    gradients = np.zeros(fc_weights.shape)\n",
    "    batch_size = input.shape[0]\n",
    "    for b in range(input.shape[0]):\n",
    "        for i in range(gradients.shape[0]):\n",
    "            for j in range(gradients.shape[1]):\n",
    "                gradients[i, j] += (-1 * (target[b, j] - pred[b, j]) * 2 * input[b, i] / gradients.shape[1] ) / batch_size\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = fc_layer(28**2, 10)\n",
    "\n",
    "lr=1e-2\n",
    "batch_size = 4\n",
    "num_samples = len(train_data)\n",
    "losses = []\n",
    "\n",
    "for i in range(num_samples // batch_size):\n",
    "    input = np.zeros((batch_size, 28**2))\n",
    "    targets = np.zeros((batch_size, 10))\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        # load img\n",
    "        img = np.array(train_data.__getitem__(i*batch_size + j)[0]) / 255.\n",
    "        img = img.flatten()\n",
    "        input[j] = img\n",
    "\n",
    "        # load labels\n",
    "        label = np.array(train_data.__getitem__(i*batch_size + j)[1])\n",
    "        label = label_one_hot_encoding(label)\n",
    "        targets[j] = label\n",
    "\n",
    "    pred = fc.forward(input)\n",
    "    pred = softmax(pred)\n",
    "    loss = mse(targets, pred)\n",
    "    losses.append(loss)\n",
    "\n",
    "    gradients = backward_mse_to_fc(input, targets, pred, fc.weights)\n",
    "    fc.weights -= gradients*lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "test_data = MNIST(root=\"./\", train=False, transform=None, target_transform=None, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8358\n"
     ]
    }
   ],
   "source": [
    "num_test_samples = len(test_data)\n",
    "results = []\n",
    "\n",
    "for i in range(10000):\n",
    "    img = np.array(test_data.__getitem__(i)[0]) / 255.\n",
    "    img = img.flatten()\n",
    "    img = np.expand_dims(img, 0)\n",
    "\n",
    "    label = np.array(test_data.__getitem__(i)[1])\n",
    "    label = label_one_hot_encoding(label)\n",
    "    label = np.expand_dims(label, 0)\n",
    "\n",
    "    pred = fc.forward(img)\n",
    "    pred = softmax(pred)\n",
    "\n",
    "    if pred.argmax() == label.argmax():\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "print(np.mean(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
